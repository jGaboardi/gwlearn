{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of geographically weighted random forest classification modelling\n",
    "\n",
    "To-do:\n",
    "- [x] global model\n",
    "- [x] model evaluation\n",
    "- [x] bandwidth optimisation\n",
    "- [x] feature importances\n",
    "- [x] golden section bandwidth selection\n",
    "- [x] other metrics than accuracy\n",
    "- [x] generic support (logistic regression, gradient boosting)\n",
    "- [x] dedicated classes\n",
    "- [ ] local performance of models that do not support OOB\n",
    "    - [x] with logistic regression I guess we can do predict_proba and measure those on the full sample directly\n",
    "    - with gradient boosting we can't as the model has seen the data - might need to split to train/test to mimic OOB.\n",
    "- [x] logistic regression local coefficients\n",
    "- [x] (optionally) predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/__init__.py:23\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/multiarray.py:10\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/overrides.py:7\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_multiarray_umath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001b[32m     11\u001b[39m ARRAY_FUNCTIONS = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mImportError\u001b[39m: dlopen(/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/_multiarray_umath.cpython-313-darwin.so, 0x0002): Library not loaded: @rpath/libgfortran.5.dylib\n  Referenced from: <CAA510D4-816A-34E5-9021-485EF5D56159> /Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/libopenblas.0.dylib\n  Reason: tried: '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/usr/local/lib/libgfortran.5.dylib' (no such file), '/usr/lib/libgfortran.5.dylib' (no such file, not in dyld cache)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/__init__.py:114\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__config__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_config\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/__config__.py:4\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_multiarray_umath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      5\u001b[39m     __cpu_features__,\n\u001b[32m      6\u001b[39m     __cpu_baseline__,\n\u001b[32m      7\u001b[39m     __cpu_dispatch__,\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mshow_config\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/__init__.py:49\u001b[39m\n\u001b[32m     26\u001b[39m     msg = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m \u001b[33m\"\"\"\u001b[39m % (sys.version_info[\u001b[32m0\u001b[39m], sys.version_info[\u001b[32m1\u001b[39m], sys.executable,\n\u001b[32m     48\u001b[39m         __version__, exc)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.13 from \"/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/bin/python\"\n  * The NumPy version is: \"2.2.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/_multiarray_umath.cpython-313-darwin.so, 0x0002): Library not loaded: @rpath/libgfortran.5.dylib\n  Referenced from: <CAA510D4-816A-34E5-9021-485EF5D56159> /Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/libopenblas.0.dylib\n  Reason: tried: '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/_core/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/martin/dev/uscuni/gwlearn/.pixi/envs/default/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/usr/local/lib/libgfortran.5.dylib' (no such file), '/usr/lib/libgfortran.5.dylib' (no such file, not in dyld cache)\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/geopandas/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m options\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeoseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeoSeries\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeodataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeoDataFrame\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m points_from_xy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/geopandas/geoseries.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, Optional\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Series\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/uscuni/gwlearn/.pixi/envs/default/lib/python3.13/site-packages/numpy/__init__.py:119\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    116\u001b[39m     msg = \u001b[33m\"\"\"\u001b[39m\u001b[33mError importing numpy: you should not try to import numpy from\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[33m    its source directory; please exit the numpy source tree, and relaunch\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[33m    your python interpreter from there.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _core\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    123\u001b[39m     False_, ScalarType, True_,\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mabs\u001b[39m, absolute, acos, acosh, add, \u001b[38;5;28mall\u001b[39m, allclose,\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m     vecmat, void, vstack, where, zeros, zeros_like\n\u001b[32m    170\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there."
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geodatasets import get_path\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "from gwlearn import BandwidthSearch\n",
    "from gwlearn.ensemble import GWGradientBoostingClassifier, GWRandomForestClassifier\n",
    "from gwlearn.linear_model import GWLogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(get_path(\"geoda.ncovr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is in the geographic coords in the  US and we need to work with distances. Re-project and use only points as the graph builder will require points anyway.\n",
    "gdf = gdf.set_geometry(gdf.representative_point()).to_crs(5070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = gdf[\"FH90\"] > gdf[\"FH90\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf = GWRandomForestClassifier(\n",
    "    bandwidth=250,\n",
    "    fixed=False,\n",
    "    n_jobs=-1,\n",
    "    keep_models=False,\n",
    ")\n",
    "gwrf.fit(\n",
    "    gdf.iloc[:, 9:15],\n",
    "    y,\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global OOB accuracy for the GW model measured based on OOB predictions from individual local trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.oob_precision_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.oob_recall_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.oob_balanced_accuracy_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local OOB accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.local_oob_score_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.local_oob_precision_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.local_oob_recall_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.local_oob_balanced_accuracy_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.local_oob_f1_macro_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.local_oob_f1_micro_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.local_oob_f1_weighted_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.focal_proba_[True], legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(y, legend=True, s=2, cmap=\"Set1_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global accuracy for the GW model measured based on prediction of focals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores for the GW model measured based on prediction of focals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.f1_macro_, gwrf.f1_micro_, gwrf.f1_weighted_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score (accuracy) of the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.global_model.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get local feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.feature_importances_[\"HC60\"], legend=True, s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to global feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.global_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwgb = GWGradientBoostingClassifier(\n",
    "    bandwidth=250,\n",
    "    fixed=False,\n",
    "    n_jobs=-1,\n",
    "    keep_models=False,\n",
    ")\n",
    "gwgb.fit(\n",
    "    gdf.iloc[:, 9:15],\n",
    "    y,\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global score (accuracy) for the GW model measured based on prediction of focals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwgb.score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores for the GW model measured based on prediction of focals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwgb.f1_macro_, gwgb.f1_micro_, gwgb.f1_weighted_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get local feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwgb.feature_importances_[\"HR90\"], legend=True, s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to global feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwgb.global_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr = GWLogisticRegression(\n",
    "    bandwidth=900_000,\n",
    "    fixed=True,\n",
    "    n_jobs=-1,\n",
    "    keep_models=True,\n",
    "    max_iter=500,\n",
    ")\n",
    "gwlr.fit(\n",
    "    pd.DataFrame(\n",
    "        preprocessing.scale(gdf.iloc[:, 9:15]), columns=gdf.iloc[:, 9:15].columns\n",
    "    ),\n",
    "    gdf[\"FH90\"] > gdf[\"FH90\"].median(),\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr.pred_f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwlr.local_pred_f1_micro_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr.f1_macro_, gwlr.f1_micro_, gwlr.f1_weighted_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr.local_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwlr.local_coef_[\"HR90\"], legend=True, s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwlr.local_intercept_, s=2, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandwidth search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Golden section search with a fixed distance bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BandwidthSearch(\n",
    "    GWRandomForestClassifier,\n",
    "    fixed=True,\n",
    "    n_jobs=-1,\n",
    "    search_method=\"golden_section\",\n",
    "    criterion=\"aic\",\n",
    "    max_iterations=10,\n",
    "    min_bandwidth=250_000,\n",
    "    max_bandwidth=2_000_000,\n",
    "    verbose=True,\n",
    ")\n",
    "search.fit(\n",
    "    gdf.iloc[:, 9:15],\n",
    "    y,\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.optimal_bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Golden section search with an adaptive KNN bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BandwidthSearch(\n",
    "    GWLogisticRegression,\n",
    "    fixed=False,\n",
    "    n_jobs=-1,\n",
    "    search_method=\"interval\",\n",
    "    min_bandwidth=10,\n",
    "    max_bandwidth=3084,\n",
    "    interval=200,\n",
    "    criterion=\"aic\",\n",
    "    verbose=True,\n",
    "    max_iter=500,  # passed to log regr\n",
    ")\n",
    "search.fit(\n",
    "    pd.DataFrame(\n",
    "        preprocessing.scale(gdf.iloc[:, 9:15]), columns=gdf.iloc[:, 9:15].columns\n",
    "    ),\n",
    "    y,\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.scores_.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.oob_scores.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.optimal_bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "If you want to use the model for prediction, all the local models need to be retained. That may require significant memory for RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr = GWLogisticRegression(\n",
    "    bandwidth=1210,\n",
    "    fixed=False,\n",
    "    n_jobs=-1,\n",
    "    # search_method=\"golden_section\",\n",
    "    # criterion=\"aic\",\n",
    "    # max_iterations=10,\n",
    "    # tolerance=0.1,\n",
    "    verbose=True,\n",
    "    max_iter=500,  # passed to log regr\n",
    "    measure_performance=False,\n",
    ")\n",
    "gwlr.fit(\n",
    "    pd.DataFrame(\n",
    "        preprocessing.scale(gdf.iloc[:, 9:15]), columns=gdf.iloc[:, 9:15].columns\n",
    "    ),\n",
    "    gdf[\"FH90\"] > gdf[\"FH90\"].median(),\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame(\n",
    "    preprocessing.scale(gdf.iloc[:, 9:15]), columns=gdf.iloc[:, 9:15].columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = gwlr.predict_proba(all_data.iloc[:10], geometry=gdf.geometry.iloc[:10])\n",
    "pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict label (taking max of probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr.predict(all_data.iloc[5:10], geometry=gdf.geometry.iloc[5:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
